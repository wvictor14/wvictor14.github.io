[
  {
    "objectID": "projects/planet/index.html",
    "href": "projects/planet/index.html",
    "title": "planet",
    "section": "",
    "text": "An R package for all of the bioinformatic tools I created from my PhD. They all use epigenetic patterns to predict: cell composition, ethnicity, age, and disease (preeclampsia), all from using placental DNA methylation data as input.\n\nplanet R package\nsource"
  },
  {
    "objectID": "projects/rbiotechsalary/index.html",
    "href": "projects/rbiotechsalary/index.html",
    "title": "rbiotechsalary",
    "section": "",
    "text": "In 2022 I pulled reddit’s r/biotech salary survey data to inform my job search. It involved extensive data cleaning, and ultimately was very useful information for a new graduate job seeker. Over time, I used this dataset to explore software, data visualization, and data science methods for my own personal interest. Some of these explorations I’ve shared here.\nThe raw data is a live google excel file connected to a google form survey. The excel file is automatically pulled every week using github actions, and an ETL script (source) publishes the dataset to github as a flat file (csv). The ETL script (quarto markdown document) also publishes the rendered ETL script using quarto here, which can be conveniently used to examine the different steps of the ETL pipeline in detail if needed.\nTo explore the data, I built a shiny app, which is a deployed docker container hosted on a digital ocean droplet. The app reads in the data from the flat file hosted on github. The app has interactive controls to filter the data and examine salary and other survey response information.\nI also have used this dataset to explore using observable js to build dashboards"
  },
  {
    "objectID": "projects/placentalmethylomebrowser/index.html",
    "href": "projects/placentalmethylomebrowser/index.html",
    "title": "Placental Methylome Browser",
    "section": "",
    "text": "A mini project where me and one of my students Yifan Yin created a shiny app to explore epigenetic data from placental samples we collected.\nI no longer maintain this app, but it usually lives here:\nrobinsonlab.shinyapps.io/Placental_Methylome_Browser/\nsource"
  },
  {
    "objectID": "posts/2024-02-24-read-1-gene-from-single-cell/index.html",
    "href": "posts/2024-02-24-read-1-gene-from-single-cell/index.html",
    "title": "Quickly reading 1 gene at a time from single cell data",
    "section": "",
    "text": "“Can you check gene x for me?” says every scientist I ever did RNAseq analysis for.\nThis is a port from my old website so formatting is not great."
  },
  {
    "objectID": "posts/index.html",
    "href": "posts/index.html",
    "title": "Posts",
    "section": "",
    "text": "Some attempts have been made at blogging\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n2025 Posit Plotnine and Great Tables Contest Submission\n\n\n\nR\n\ndata visualization\n\nbioinformatics\n\n\n\nMy submissions to the 2025 plotnine and table contests: exploring the uncertain canadian job market with plotnine, and visualizing multiple sequence alignment with gt\n\n\n\n\n\nOct 3, 2025\n\n2 min\n\n\n\n\n\n\n\n\n\n\n\nProgrammatically creating tabsets in R\n\n\n\nR\n\nquarto\n\n\n\n\n\n\n\n\n\nMar 28, 2025\n\n4 min\n\n\n\n\n\n\n\n\n\n\n\nMaking a Twitter Bot in the Year 2024\n\n\n\nR\n\nshiny\n\n\n\n\n\n\n\n\n\nJun 12, 2024\n\n3 min\n\n\n\n\n\n\n\n\n\n\n\nQuickly reading 1 gene at a time from single cell data\n\n\n\nR\n\nbioinformatics\n\n\n\n\n\n\n\n\n\nFeb 24, 2024\n\n1 min\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/2025-10-03-2025-posit-plotnine-and-great-tables-contest/index.html",
    "href": "posts/2025-10-03-2025-posit-plotnine-and-great-tables-contest/index.html",
    "title": "2025 Posit Plotnine and Great Tables Contest Submission",
    "section": "",
    "text": "On August 21 2025, Posit announced the 2025 Table and Plotnine contests. I was always impressed with the resulting submissions from previous years, so this year I decided to participate.\nInitially, I decided that the plotnine contest sounded like a great opportunity to see how to use the python port of ggplot2. I had no experience with plotnine, but lots with ggplot2.\nHowever, after finishing my submission for plotnine, I turned my attention to the table contest. I wasn’t certain if I had the time to make another high quality submission. But I felt that I had a great idea that I haven’t seen done before. So I reconsidered and decided to make a smaller single post entry for the table contest.\n\nExploring Canada Job Market Data with plotnine\nFor the 2025 plotnine contest, I wanted to explore official Canadian labour statistics using Plotnine.\nUsing quarto, I created a website, which hosts the final submitted visualization, and a tutorial on how I developed the visualization.\nThe visualization uses the plotnine, which is a visualization library from python, heavily inspired by the grammar of graphics. I used polars to crunch the data.\n\n\n\nCoronavirus Spike Proteins with r-gt\nFor the 2025 Posit Table contest I wanted to explore how MSAs can be effectively visualized using the r package gt. This has been something I have wanted to do for a long time, and felt like this would be great way to share some of the exploration with the community.\nsubmission"
  },
  {
    "objectID": "posts/2024-06-12-making-a-twitter-bot-in-the-year-2024/index.html",
    "href": "posts/2024-06-12-making-a-twitter-bot-in-the-year-2024/index.html",
    "title": "Making a Twitter Bot in the Year 2024",
    "section": "",
    "text": "Except, because it is 2024, using Twitter is uncool, so what I actually did instead was, I made a Mastodon Bot. It’s powered by github actions, meaning everyday it automatically pulls data from BC open map data, detects new vacancies using R, and sends a “toot” (that’s the mastodon word for “tweet”) to this account."
  },
  {
    "objectID": "posts/2024-06-12-making-a-twitter-bot-in-the-year-2024/index.html#i-made-a-twitter-bot-the-bc-child-care-bot",
    "href": "posts/2024-06-12-making-a-twitter-bot-in-the-year-2024/index.html#i-made-a-twitter-bot-the-bc-child-care-bot",
    "title": "Making a Twitter Bot in the Year 2024",
    "section": "",
    "text": "Except, because it is 2024, using Twitter is uncool, so what I actually did instead was, I made a Mastodon Bot. It’s powered by github actions, meaning everyday it automatically pulls data from BC open map data, detects new vacancies using R, and sends a “toot” (that’s the mastodon word for “tweet”) to this account."
  },
  {
    "objectID": "posts/2024-06-12-making-a-twitter-bot-in-the-year-2024/index.html#what-is-mastodon",
    "href": "posts/2024-06-12-making-a-twitter-bot-in-the-year-2024/index.html#what-is-mastodon",
    "title": "Making a Twitter Bot in the Year 2024",
    "section": "What is Mastodon",
    "text": "What is Mastodon\nIf you’re like me and were not an avid Twitter user in the first place, you probably have never heard of Mastodon.\nWell, Mastodon is basically Twitter - you create an account, follow people, and see posts from things you follow.\nBut unlike Twitter, the servers are decentralized, meaning nothing like what Elon did to Twitter can happen, because no single person “owns” all of the servers. Or something like that."
  },
  {
    "objectID": "posts/2024-06-12-making-a-twitter-bot-in-the-year-2024/index.html#why",
    "href": "posts/2024-06-12-making-a-twitter-bot-in-the-year-2024/index.html#why",
    "title": "Making a Twitter Bot in the Year 2024",
    "section": "Why",
    "text": "Why\nAnyways, I don’t really care much about Mastodon / Twitter / X or whatever. The main reason I made a the BC Child Care Bot was so that I could help my wife find day care vacancies for my son. And after struggling with deployment challenges in my previous project, I was interested in CICD and other cool things you can do with github actions."
  },
  {
    "objectID": "posts/2024-06-12-making-a-twitter-bot-in-the-year-2024/index.html#how",
    "href": "posts/2024-06-12-making-a-twitter-bot-in-the-year-2024/index.html#how",
    "title": "Making a Twitter Bot in the Year 2024",
    "section": "How",
    "text": "How\n\nGithub Actions\nI followed this post closely to learn how to make my own workflow. Essentially it uses github actions to run an R script in the github repository on a daily basis (a cron job).\nThis is the section that configures the cron job. I also set it up so that on a certain branch named “test”, the script will run. I use this for testing that the workflow works, without having to change the cron schedule everytime.\non:\n  push:\n    branches: ['test'] # push to this branch to test toots\n  schedule:\n    - cron: '41 15 * * *'  # trigger at 3pm UTC  every day\nThe other necessary component is to add mastdon API token to github repository as a “github secret”. Then in the workflow, the token is used with the following syntax:\n${{ secrets.RTOOT_DEFAULT_TOKEN}}\n\n\nYay for open source\nThe last component is making the R script to: pull data, identify NEW vacancies, create a tweet / toot to send.\nI pulled data from BC gov’s open data portal, and figured out a way to ID new vacancies. Then, a message is crafted accounting for the character limits (500) for mastodon toots.\nActually the character limit is quite restrictive. Every day there can be 50-150 new vacancies over BC, depending on child care age group. But we only have 1 child (thank) so currently the bot only reports facilities with vacancy for children aged &lt;36 months.\nEvery day this dataset is updated at this URL. The whole script depends on whether this URL stays the same. If it changes, the bot will stop working. Fingers crossed!"
  },
  {
    "objectID": "posts/2025-03-28-dynamic-navsets/index.html#render-the-tab-names-and-content-server-side",
    "href": "posts/2025-03-28-dynamic-navsets/index.html#render-the-tab-names-and-content-server-side",
    "title": "Programmatically creating tabsets in R",
    "section": "Render the tab names and content server-side",
    "text": "Render the tab names and content server-side\nNext is the server code. The server code does 3 things:\n\nfilter the penguins dataset penguin_filtered, based on the radio buttons\ndynamically render the ui component based on the island column in the filter penguin dataset i.e. penguin_filtered$island\nCreate content for each tab, here I chose a histogram over year.\n\n\nserver &lt;- function(session, input, output) {\n  # 1. filter by species\n  penguins_filtered &lt;- reactive({\n    req(input$select_species)\n    penguins |&gt; filter(species == input$select_species)\n  })\n\n  # 2. create the ui based on the `island` column\n  output$dynamic_navset_card &lt;- renderUI({\n    nav_items &lt;- unique(penguins_filtered()$island) |&gt; purrr::map(\n      ~ nav_panel(\n        title = .x,\n        plotOutput(glue(\"plot_{.x}\"))\n      )\n    )\n    navset_card_pill(!!!nav_items)\n  })\n\n  # 3. create the plots\n  observe({\n    walk(\n      unique(penguins_filtered()$island),\n      function(x) {\n        id &lt;- glue(\"plot_{x}\")\n        output[[id]] &lt;- renderPlot({\n          penguins_filtered() |&gt;\n            filter(island == x) |&gt;\n            ggplot(aes(x = year)) +\n            geom_histogram(stat = \"count\") +\n            labs(title = glue(\"Number of penguins by year for island {x}\"))\n        })\n      }\n    )\n  })\n}\n\nThe tricky part is figuring out how to dynamically assign the output ids. Here, I programmatically create the ids and then assign them content (plots) based on the relevant subset of data."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Victor Yuan",
    "section": "",
    "text": "Hello! It’s nice to meet you. I am a bioinformatics data scientist at Sonoma Biotherapeutics where I use data science to help develop cell therapies to cure autoimmune diseases. I love making beautiful charts, developing reproducible scientific content, climbing boulders, and drinking specialty coffees.\nI studied epigenetics and placental biology, completing my PhD at University of British Columbia, Canada in 2022. Before that I did my BSc in molecular biology at Concordia University, Montreal."
  },
  {
    "objectID": "projects/bcchildcarebot/index.html",
    "href": "projects/bcchildcarebot/index.html",
    "title": "BC Child Care Vacancies Dashboard + Mastodon Bot",
    "section": "",
    "text": "A data scientist finds childcare.\nThis 2 part project extracts and deliveries child care vacancies using open-source BC childcare dataset. It uses github actions to automatically pull the updated data every day to\n\npost to mastodon new vacancies, and\ndisplay vacancies in a webpage\n\n\nMastodon bot\nLast updated: 2024-06-09\n\nBlog post for the bot\nMastodon bot\nsource\n\n\n\nDashboard\nLast updated: 2025-03-20 (the source, but the data is updated every day)\n\nDashboard\nsource"
  },
  {
    "objectID": "projects/index.html",
    "href": "projects/index.html",
    "title": "Projects",
    "section": "",
    "text": "Some of my public projects.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nBC Child Care Vacancies Dashboard + Mastodon Bot\n\n\n\n\n\n\n\n\nJun 9, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nrbiotechsalary\n\n\n\n\n\n\n\n\nMay 15, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nplanet\n\n\n\n\n\n\n\n\nJan 1, 2020\n\n\n\n\n\n\n\n\n\n\n\n\nPlacental Methylome Browser\n\n\n\n\n\n\n\n\nJan 1, 2019\n\n\n\n\n\nNo matching items"
  }
]